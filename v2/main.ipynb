{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: youtube-transcript-api in ./.venv/lib/python3.11/site-packages (0.6.2)\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.11/site-packages (from youtube-transcript-api) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.11/site-packages (from requests->youtube-transcript-api) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.11/site-packages (from requests->youtube-transcript-api) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.11/site-packages (from requests->youtube-transcript-api) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.11/site-packages (from requests->youtube-transcript-api) (2024.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: groq in ./.venv/lib/python3.11/site-packages (0.5.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in ./.venv/lib/python3.11/site-packages (from groq) (4.3.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./.venv/lib/python3.11/site-packages (from groq) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./.venv/lib/python3.11/site-packages (from groq) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in ./.venv/lib/python3.11/site-packages (from groq) (2.7.1)\n",
      "Requirement already satisfied: sniffio in ./.venv/lib/python3.11/site-packages (from groq) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in ./.venv/lib/python3.11/site-packages (from groq) (4.11.0)\n",
      "Requirement already satisfied: idna>=2.8 in ./.venv/lib/python3.11/site-packages (from anyio<5,>=3.5.0->groq) (3.7)\n",
      "Requirement already satisfied: certifi in ./.venv/lib/python3.11/site-packages (from httpx<1,>=0.23.0->groq) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.11/site-packages (from httpx<1,>=0.23.0->groq) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./.venv/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in ./.venv/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->groq) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in ./.venv/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->groq) (2.18.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: flask in ./.venv/lib/python3.11/site-packages (3.0.3)\n",
      "Requirement already satisfied: Werkzeug>=3.0.0 in ./.venv/lib/python3.11/site-packages (from flask) (3.0.2)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in ./.venv/lib/python3.11/site-packages (from flask) (3.1.3)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in ./.venv/lib/python3.11/site-packages (from flask) (2.2.0)\n",
      "Requirement already satisfied: click>=8.1.3 in ./.venv/lib/python3.11/site-packages (from flask) (8.1.7)\n",
      "Requirement already satisfied: blinker>=1.6.2 in ./.venv/lib/python3.11/site-packages (from flask) (1.8.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.11/site-packages (from Jinja2>=3.1.2->flask) (2.1.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: googlesearch-python in ./.venv/lib/python3.11/site-packages (1.2.4)\n",
      "Requirement already satisfied: beautifulsoup4>=4.9 in ./.venv/lib/python3.11/site-packages (from googlesearch-python) (4.12.3)\n",
      "Requirement already satisfied: requests>=2.20 in ./.venv/lib/python3.11/site-packages (from googlesearch-python) (2.31.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in ./.venv/lib/python3.11/site-packages (from beautifulsoup4>=4.9->googlesearch-python) (2.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.11/site-packages (from requests>=2.20->googlesearch-python) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.11/site-packages (from requests>=2.20->googlesearch-python) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.11/site-packages (from requests>=2.20->googlesearch-python) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.11/site-packages (from requests>=2.20->googlesearch-python) (2024.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: duckduckgo-search in ./.venv/lib/python3.11/site-packages (5.3.0)\n",
      "Requirement already satisfied: click>=8.1.7 in ./.venv/lib/python3.11/site-packages (from duckduckgo-search) (8.1.7)\n",
      "Requirement already satisfied: curl-cffi>=0.6.2 in ./.venv/lib/python3.11/site-packages (from duckduckgo-search) (0.6.3)\n",
      "Requirement already satisfied: orjson>=3.10.0 in ./.venv/lib/python3.11/site-packages (from duckduckgo-search) (3.10.1)\n",
      "Requirement already satisfied: cffi>=1.12.0 in ./.venv/lib/python3.11/site-packages (from curl-cffi>=0.6.2->duckduckgo-search) (1.16.0)\n",
      "Requirement already satisfied: certifi>=2024.2.2 in ./.venv/lib/python3.11/site-packages (from curl-cffi>=0.6.2->duckduckgo-search) (2024.2.2)\n",
      "Requirement already satisfied: pycparser in ./.venv/lib/python3.11/site-packages (from cffi>=1.12.0->curl-cffi>=0.6.2->duckduckgo-search) (2.22)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: youtube-search-python in ./.venv/lib/python3.11/site-packages (1.6.6)\n",
      "Requirement already satisfied: httpx>=0.14.2 in ./.venv/lib/python3.11/site-packages (from youtube-search-python) (0.27.0)\n",
      "Requirement already satisfied: anyio in ./.venv/lib/python3.11/site-packages (from httpx>=0.14.2->youtube-search-python) (4.3.0)\n",
      "Requirement already satisfied: certifi in ./.venv/lib/python3.11/site-packages (from httpx>=0.14.2->youtube-search-python) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.11/site-packages (from httpx>=0.14.2->youtube-search-python) (1.0.5)\n",
      "Requirement already satisfied: idna in ./.venv/lib/python3.11/site-packages (from httpx>=0.14.2->youtube-search-python) (3.7)\n",
      "Requirement already satisfied: sniffio in ./.venv/lib/python3.11/site-packages (from httpx>=0.14.2->youtube-search-python) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./.venv/lib/python3.11/site-packages (from httpcore==1.*->httpx>=0.14.2->youtube-search-python) (0.14.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: langchain-experimental in ./.venv/lib/python3.11/site-packages (0.0.57)\n",
      "Requirement already satisfied: langchain<0.2.0,>=0.1.15 in ./.venv/lib/python3.11/site-packages (from langchain-experimental) (0.1.16)\n",
      "Requirement already satisfied: langchain-core<0.2.0,>=0.1.41 in ./.venv/lib/python3.11/site-packages (from langchain-experimental) (0.1.46)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./.venv/lib/python3.11/site-packages (from langchain<0.2.0,>=0.1.15->langchain-experimental) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in ./.venv/lib/python3.11/site-packages (from langchain<0.2.0,>=0.1.15->langchain-experimental) (2.0.29)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in ./.venv/lib/python3.11/site-packages (from langchain<0.2.0,>=0.1.15->langchain-experimental) (3.9.5)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in ./.venv/lib/python3.11/site-packages (from langchain<0.2.0,>=0.1.15->langchain-experimental) (0.6.4)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./.venv/lib/python3.11/site-packages (from langchain<0.2.0,>=0.1.15->langchain-experimental) (1.33)\n",
      "Requirement already satisfied: langchain-community<0.1,>=0.0.32 in ./.venv/lib/python3.11/site-packages (from langchain<0.2.0,>=0.1.15->langchain-experimental) (0.0.34)\n",
      "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in ./.venv/lib/python3.11/site-packages (from langchain<0.2.0,>=0.1.15->langchain-experimental) (0.0.1)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in ./.venv/lib/python3.11/site-packages (from langchain<0.2.0,>=0.1.15->langchain-experimental) (0.1.51)\n",
      "Requirement already satisfied: numpy<2,>=1 in ./.venv/lib/python3.11/site-packages (from langchain<0.2.0,>=0.1.15->langchain-experimental) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in ./.venv/lib/python3.11/site-packages (from langchain<0.2.0,>=0.1.15->langchain-experimental) (2.7.1)\n",
      "Requirement already satisfied: requests<3,>=2 in ./.venv/lib/python3.11/site-packages (from langchain<0.2.0,>=0.1.15->langchain-experimental) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in ./.venv/lib/python3.11/site-packages (from langchain<0.2.0,>=0.1.15->langchain-experimental) (8.2.3)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in ./.venv/lib/python3.11/site-packages (from langchain-core<0.2.0,>=0.1.41->langchain-experimental) (23.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.15->langchain-experimental) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.15->langchain-experimental) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.15->langchain-experimental) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.15->langchain-experimental) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.15->langchain-experimental) (1.9.4)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./.venv/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain<0.2.0,>=0.1.15->langchain-experimental) (3.21.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in ./.venv/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain<0.2.0,>=0.1.15->langchain-experimental) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./.venv/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain<0.2.0,>=0.1.15->langchain-experimental) (2.4)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in ./.venv/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.17->langchain<0.2.0,>=0.1.15->langchain-experimental) (3.10.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in ./.venv/lib/python3.11/site-packages (from pydantic<3,>=1->langchain<0.2.0,>=0.1.15->langchain-experimental) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in ./.venv/lib/python3.11/site-packages (from pydantic<3,>=1->langchain<0.2.0,>=0.1.15->langchain-experimental) (2.18.2)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in ./.venv/lib/python3.11/site-packages (from pydantic<3,>=1->langchain<0.2.0,>=0.1.15->langchain-experimental) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.11/site-packages (from requests<3,>=2->langchain<0.2.0,>=0.1.15->langchain-experimental) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.11/site-packages (from requests<3,>=2->langchain<0.2.0,>=0.1.15->langchain-experimental) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.11/site-packages (from requests<3,>=2->langchain<0.2.0,>=0.1.15->langchain-experimental) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.11/site-packages (from requests<3,>=2->langchain<0.2.0,>=0.1.15->langchain-experimental) (2024.2.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in ./.venv/lib/python3.11/site-packages (from SQLAlchemy<3,>=1.4->langchain<0.2.0,>=0.1.15->langchain-experimental) (3.0.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./.venv/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain<0.2.0,>=0.1.15->langchain-experimental) (1.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install youtube-transcript-api\n",
    "%pip install groq\n",
    "%pip install flask\n",
    "%pip install googlesearch-python\n",
    "%pip install duckduckgo-search\n",
    "%pip install youtube-search-python\n",
    "%pip install langchain-experimental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in ./.venv/lib/python3.11/site-packages (4.20.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in ./.venv/lib/python3.11/site-packages (from urllib3[socks]<3,>=1.26->selenium) (2.2.1)\n",
      "Requirement already satisfied: trio~=0.17 in ./.venv/lib/python3.11/site-packages (from selenium) (0.25.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in ./.venv/lib/python3.11/site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in ./.venv/lib/python3.11/site-packages (from selenium) (2024.2.2)\n",
      "Requirement already satisfied: typing_extensions>=4.9.0 in ./.venv/lib/python3.11/site-packages (from selenium) (4.11.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in ./.venv/lib/python3.11/site-packages (from trio~=0.17->selenium) (23.2.0)\n",
      "Requirement already satisfied: sortedcontainers in ./.venv/lib/python3.11/site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in ./.venv/lib/python3.11/site-packages (from trio~=0.17->selenium) (3.7)\n",
      "Requirement already satisfied: outcome in ./.venv/lib/python3.11/site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in ./.venv/lib/python3.11/site-packages (from trio~=0.17->selenium) (1.3.1)\n",
      "Requirement already satisfied: wsproto>=0.14 in ./.venv/lib/python3.11/site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in ./.venv/lib/python3.11/site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in ./.venv/lib/python3.11/site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googlesearch import search\n",
    "from openai import OpenAI\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "from flask import Flask, request, jsonify\n",
    "from duckduckgo_search import AsyncDDGS, DDGS\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from groq import Groq\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "\n",
    "app = Flask(__name__)\n",
    "client = OpenAI(api_key=\"sk-proj-t8zmYeKLmyl7Jj1JuCTsT3BlbkFJYNmTpjCTi05I0So7HHOC\")\n",
    "groqclient=Groq(api_key=\"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\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Music]welcome to the entrepreneurial thoughtleader seminar at StanfordUniversity this is the Stanford seminarfor aspiring entrepreneurs ETL isbrought to you by stvp the Stanfordentrepreneurship engineering center andbasis The Business Association ofStanford entrepreneurial students I'mrvie balani a lecturer in the managementscience and engineering department andthe director of Alchemist andaccelerator for Enterprise startups andtoday I have the pleasure of welcomingSam Altman to ETLum Sam is the co-founder and CEO of openAI open is not a word I would use todescribe the seats in this class and soI think by virtue of that that everybodyalready play knows open AI but for thosewho don't openai is the research anddeployment company behind chat gbt Dollyand Sora um Sam's life is a pattern ofbreaking boundaries and transcendingwhat's possible both for himself and forthe world he grew up in the midwest inSt Louis came to Stanford took ETL as anundergrad um for any and we we held onto Stanford or Sam for two years hestudied computer science and then afterhis sophomore year he joined theinaugural class of Y combinator with aSocial Mobile app company called loopedum that then went on to go raise moneyfrom Sequoia and others he then droppedout of Stanford spent seven years onlooped which got Acquired and then herejoined Y combinator in an operationalrole he became the president of Ycombinator from 2014 to 2019 and then in2015 he co-founded open aai as anonprofit research lab with the missionto build general purpose artificialintelligence that benefits all Humanityopen aai has set the record for thefastest growing app in history with thelaunch of chat gbt which grew to 100million active users just two monthsafter launch Sam was named one oftimes's 100 most influential people inthe world he was also named times CEO ofthe year in 2023 and he was also mostrecently added to Forbes list of theworld's billionaires um Sam lives withhis husband in San Francisco and splitshis time between San Francisco and Napaand he's also a vegetarian and so withthat please join me in welcoming SamAltman to the stageand in full disclosure that was a longerintroduction than Sam probably wouldhave liked um brevity is the soul of witum and so we'll try to make thequestions more concise but this is thisis this is also Sam's birth week it's itwas his birthday on Monday and Imentioned that just because I think thisis an auspicious moment both in terms oftime you're 39 now and also place you'reat Stanford in ETL that I would beremiss if this wasn't sort of a momentof just some reflection and I'm curiousif you reflect back on when you werehalf a lifee younger when you were 19 inETL um if there were three words todescribe what your felt sense was likeas a Stanford undergrad what would thosethree words be it's always hardquestionsum I was like ex uh you want three wordsonly okay uh you can you can go more Samyou're you're the king of brevity uhexcited optimistic and curious okay andwhat would be your three wordsnow I guess the same which is terrificso there's been a constant thread eventhough the world has changed and youknow a lot has changed in the last 19years but that's going to pale incomparison what's going to happen in thenext 19 yeah and so I need to ask youfor your advice if you were a Stanfordundergrad today so if you had a FreakyFriday moment tomorrow you wake up andsuddenly you're 19 in inside of Stanfordundergrad knowing everything you knowwhat would you do would you drop be veryhappy um I would feel like I was likecoming of age at the luckiest timeum like in several centuries probably Ithink the degree to which the world isis going to change and the theopportunity to impact that um starting acompany doing AI research any number ofthings is is like quite remarkable Ithink this is probably the best time tostart I yeah I think I would say this Ithink this is probably the best time tostart a companies since uh the internetat least and maybe kind of like in thehistory of technology I think with whatyou can do with AI is like going to justget more remarkable every year and thegreatest companies get created at timeslike this the most impactful newproducts get built at times like this soum I would feel incredibly lucky uh andI would be determined to make the mostof it and I would go figure out likewhere I wanted to contribute and do itand do you have a bias on where wouldyou contribute would you want to stay asa student um would and if so would youmajor in a certain major giving the paceof of change probably I would not stayas a student but only cuz like I didn'tand I think it's like reasonable toassume people kind of are going to makethe same decisions they would make againum I think staying as a student is aperfectly good thing to do I just I itwould probably not be what I would havepicked no this is you this is you so youhave the Freaky Friday moment it's youyou're reborn and as a 19-year-old andwould youyeah what I think I would again like Ithink this is not a surprise cuz peoplekind of are going to do what they'regoing to do I think I would go work onresearch and and and where might you dothat Sam I think I mean obviously I havea bias towards open eye but I thinkanywhere I could like do meaningful AIresearch I would be like very thrilledabout but you'd be agnostic if that'sAcademia or Private Industryum I say this with sadness I think Iwould pickindustry realistically um I think it's Ithink to you kind of need to be theplace with so much compute M MH okay andum if you did join um on the researchside would you join so we had kazer herelast week who was a big advocate of notbeing a Founder but actually joining anexisting companies sort of learn learnthe chops for the for the students thatare wrestling with should I start acompany now at 19 or 20 or should I gojoin another entrepreneurial eitherresearch lab or Venture what advicewould you give them well since he gavethe case to join a company I'll give theother one um which is I think you learna lot just starting a company and ifthat's something you want to do at somepoint there's this thing Paul Grahamsays but I think it's like very deeplytrue there's no pre-startup like thereis Premed you kind of just learn how torun a startup by running a startup andif if that's what you're pretty sure youwant to do you may as well jump in anddo it and so let's say so if somebodywants to start a company they want to bein AI um what do you think are thebiggest near-term challenges that you'reseeing in AI that are the ripest for astartup and just to scope that what Imean by that are what are the holes thatyou think are the top priority needs foropen AI that open AI will not solve inthe next three years um yeahso I think this is like a veryreasonable question to ask in some sensebut I think it's I'm not going to answerit because I think you shouldnever take this kind of advice aboutwhat startup to start ever from anyoneum I think by the time there's somethingthat is like the kind of thing that'sobvious enough that me or somebody elsewill sit up here and say it it'sprobably like not that great of astartup idea and I totally understandthe impulse and I remember when I wasjust like asking people like whatstartup should I startum but I I think like one of the mostimportant things I believe about havingan impactful career is you have to chartyour own course if if the thing thatyou're thinking about is something thatsomeone else is going to do anyway ormore likely something that a lot ofpeople are going to do anywayum you should be like somewhat skepticalof that and I think a really good muscleto build is coming up with the ideasthat are not the obvious ones to say soI don't know what the really importantidea is that I'm not thinking of rightnow but I'm very sure someone in thisroom does it knows what that answer isum and I think learning to trustyourself and come up with your own ideasand do the very like non-consensusthings like when we started open AI thatwas an extremely non-consensus thing todo and now it's like the very obviousthing to do um now I only have theobvious ideas CU I'm just like stuck inthis one frame but I'm sure you all havethe otherones but are there so can I ask itanother way and I don't know if this isfair or not but are what questions thenare you wrestling with that no one elseis talkingabout how to build really big computersI mean I think other people are talkingabout that but we're probably likelooking at it through a lens that no oneelse is quite imagining yet umI mean we're we're definitely wrestlingwith how we when we make not just likegrade school or middle schooler levelintelligence but like PhD levelintelligence and Beyond the best way toput that into a product the best way tohave a positive impact with that onsociety and people's lives we don't knowthe answer to that yet so I think that'slike a pretty important thing to figureout okay and can we continue on thatthread then of how to build really bigcomputers if that's really what's onyour mind can you share I know there'sbeen a lot of speculation and probably alot of here say too about um thesemiconductor Foundry Endeavor that youare reportedly embarking on um can youshare what would make what what's thevision what would make this differentthan it's not just foundies althoughthat that's part of it it's like if ifyou believe which we increasingly do atthis point that AI infrastructure isgoing to be one of the most importantinputs to the Future this commodity thateverybody's going to want and that isenergy data centers chips chip designnew kinds of networks it's it's how welook at that entire ecosystem um and howwe make a lot more of that and I don'tthink it'll work to just look at onepiece or another but we we got to do thewhole thing okay so there's multiple bigproblems yeah um I think like just thisis the Arc of human technologicalhistory as we build bigger and morecomplex systems and does it gross so youknow in terms of just like the computecost uh correct me if I'm wrong but chatgbt 3 was I've heard it was $100 millionto do the model um and it was 100 175billion parameters gbt 4 was cost $400million with 10x the parameters it wasalmost 4X the cost but 10x theparameters correct me adjust me you knowit I I do know it but I won oh you canyou're invited to this is Stanford Samokay um uh but the the even if you don'twant to correct the actual numbers ifthat's directionally correct um does thecost do you think keep growing with eachsubsequent yes and does it keep growingmultiplicatively uh probably I mean andso the question then becomes how do wehow do you capitalizethat well look I I kind of thinkthat giving people really capable toolsand letting them figure out how they'regoing to use this to build the future isa super good thing to do and is supervaluable and I am super willing to beton the Ingenuity of you all andeverybody else in the world to figureout what to do about this so there isprobably some more business-mindedperson than me at open AI somewhere thatis worried about how much we're spendingum but I kind ofdon't okay so that doesn't cross it soyouknow open ey is phenomenal chat gbt isphenomenal um everything else all theother models arephenomenal it burned you've earned $520million of cash last year that doesn'tconcern you in terms of thinking aboutthe economic model of how do youactually where's going to be themonetization source well first of allthat's nice of you to say but Chachi PTis not phenomenal like Chachi PT is likemildly embarrassing at best um gp4 isthe dumbest model any of you will everever have to use again by a lot um butyou know it's like important to shipearly and often and we believe initerative deployment like if we go buildAGI in a basement and then you know theworld is like kindof blissfully walking blindfolded alongum I don't think that's like I don'tthink that makes us like very goodneighbors um so I think it's importantgiven what we believe is going to happento express our view about what webelieve is going to happen um but morethan that the way to do it is to put theproduct in people's hands umand let Society co-evolve with thetechnology let Society tell us what itcollectively and people individuallywant from the technology how toproductize this in a way that's going tobe useful um where the model worksreally well where it doesn't work reallywell um give our leaders andinstitutions time to react um givepeople time to figure out how tointegrate this into their lives to learnhow to use the tool um sure some of youall like cheat on your homework with itbut some of you all probably do likevery amazing amazing wonderful thingswith it too um and as each generationgoes on uh I think that will expandand and that means that we shipimperfect products um but we we have avery tight feedback loop and we learnand we get better um and it does kind ofsuck to ship a product that you'reembarrassed about but it's much betterthan the alternative um and in this casein particular where I think we reallyowe it to society to deploy tivelyum one thing we've learned is that Aiand surprise don't go well togetherpeople don't want to be surprised peoplewant a gradual roll out and the abilityto influence these systems um that's howwe're going to do it and there maybe there could totally be things in thefuture that would change where we' thinkiterative deployment isn't such a goodstrategy um but it does feel like thecurrent best approach that we have and Ithink we've gained a lot um from fromdoing this and you know hopefully s thelarger world has gained something toowhether we burn 500 million a year or 5billion or 50 billion a year I don'tcare I genuinely don't as long as we canI think stay on a trajectory whereeventually we create way more value forsociety than that and as long as we canfigure out a way to pay the bills likewe're making AGI it's going to beexpensive it's totally worth it and soand so do you have a I hear you do youhave a vision in 2030 of what if I sayyou crushed it Sam it's 2030 you crushedit what does the world look like toyouum you know maybe in some very importantways not that different uhlike we will be back here there will belike a new set of students we'll betalking about how startups are reallyimportant and technology is really coolwe'll have this new great tool in theworld it'llfeel it would feel amazing if we got toteleport forward six years today andhave this thing that waslike smarter than humans in manysubjects and could do these complicatedtasks for us and um you know like wecould have these like complicatedprogram written or This research done orthis businessstarted uh and yet like the Sun keepsRising the like people keep having theirhuman dramas life goes on so sort oflike super different in some sense thatwe now have like abundant intelligenceat our fingertipsand then in some other sense like notdifferent at all okay and you mentionedartificial general intellig AGIartificial general intelligence and inin a previous interview you you definethat as software that could mimic themedian competence of a or the competenceof a median human for tasks yeah um canyou give me is there time if you had todo a best guess of when you think orarrange you feel like that's going tohappen I think we need a more precisedefinition of AGI for the timingquestion um because at at this pointeven with like the definition you justgave which is a reasonable one there'sthat's your I'm I'm I'm paring back whatyou um said in an interview well that'sgood cuz I'm going to criticize myselfokay um it's it's it's it's too loose ofa definition there's too much room formisinterpretation in there um to I thinkbe really useful or get at what peoplereally want like I kind of think whatpeople want to know when they say likewhat's the timeline to AGI is like whenis the world going to be super differentwhen is the rate of change going to getsuper high when is the way the economyWorks going to be really different likewhen does my life changeand that for a bunch of reasons may bevery different than we think like I cantotally imagine a world where we buildPhD level intelligence in any area andyou know we can make researchers waymore productive maybe we can even dosome autonomous research and in somesenselike that sounds like it should changethe world a lot and I can imagine thatwe do that and then we can detect nochange in global GDP growth for likeyears afterwards something like that umwhich is very strange to think about andit was not my original intuition of howthis was all going to go so I don't knowhow to give a precise timeline of whenwe get to the Milestone people careabout but when we get to systems thatare way more capable than we have rightnow one year and every year after andthat I think is the important point soI've given up on trying to give the AGItimeline but I think every year for thenext many we have dramatically morecapable systems every year um I want toask about the dangers of of AGI um andgang I know there's tons of questionsfor Sam in a few moments I'll be turningit up so start start thinking about yourquestions um a big focus on Stanfordright now is ethics and um can we talkabout you know how you perceive thedangers of AGI and specifically do youthink the biggest Danger from AGI isgoing to come from a cataclysmic eventwhich you know makes all the papers oris it going to be more subtle andpernicious sort of like you know likehow everybody has ADD right now from youknow using Tik Tok um is it are you moreconcerned about the subtle dangers orthe cataclysmic dangers um or neitherI'm more concerned about the subtledangers because I think we're morelikely to overlook those the cataclysmicdangers uh a lot of people talk aboutand a lot of people think about and Idon't want to minimize those I thinkthey're really serious and a real thingum but I think we at least know to lookout for that and spend a lot of effortum the example you gave of everybodygetting add from Tik Tok or whatever Idon't think we knew to look out for andthat that's a really hard the theunknown unknowns are really hard and soI'd worry more about those although Iworry about both and are they unknownunknowns are there any that you can namethat you're particularly worried aboutwell then I would kind of they'd beunknown unknown um you canI I am am worried just about so so eventhough I think in the short term thingschange less than we think as with othermajor Technologies in the long term Ithink they change more than we think andI am worried about what rate Society canadapt to something so new and how longit'll take us to figure out the newsocial contract versus how long we getto do it um I'm worried about that okayum I'm going to I'm going to open up soI want to ask you a question about oneof the key things that we're now tryingto ininto the curriculum as things change sorapidly is resilience that's really goodand and youknow and the Cornerstone of resilienceuh is is self-awareness and so and I'mwondering um if you feel that you'repretty self-aware of your drivingmotivations as you are embarking on thisjourney so first of all I think um Ibelieve resilience can be taught uh Ibelieve it has long been one of the mostimportant life skills um and in thefuture I think in the over the nextcouple of decades I think resilience andadaptability will be more importanttheyve been in a very long time so uh Ithink that's really great um on theself-awarenessquestion I think I'm self aware but Ithink like everybody thinks they'reself-aware and whether I am or not issort of like hard to say from the insideand can I ask you sort of the questionsthat we ask in our intro classes on selfawareness sure it's like the Peter duerframework so what do you think yourgreatest strengths areSamuh I think I'm not great at many thingsbut I'm good at a lot of things and Ithink breath has become an underratedthing in the world everyone gets likehypers specialized so if you're good ata lot of things you can seek connectionsacross them um I think you can then kindof come up with the ideas that aredifferent than everybody else has orthat sort of experts in one area haveand what are your most dangerousweaknessesum most dangerous that's an interestingframework for ituh I think I have like a general bias tobe too Pro technology just cuz I'mcurious and I want to see where it goesand I believe that technology is on thewhole a net good thing but I think thatis a worldview that has overall servedme and others well and thus got like alot of positivereinforcement and is not always true andwhen it's not been true has been likepretty bad for a lot of people and thenHarvard psychologist David mcland hasthis framework that all leaders aredriven by one of three Primal needs aneed for affiliation which is a need tobe liked a need for achievement and aneed for power if you had to rank listthose what would beyours I think at various times in mycareer all of those I think there theselike levels that people go throughum at this point I feel driven by likewanting to do something useful andinteresting okay and I definitely hadlike the money and the power and thestatus phases okay and then where wereyou when you most last felt most likeyourself I Ialways and then one last question andwhat are you most excited about withchat gbt five that's coming out that uhpeopledon't what are you what are you mostexcited about with the of chat gbt thatwe're all going to seeuh I don't know yet um I I mean I thisthis sounds like a cop out answer but Ithink the most important thing about gp5or whatever we call that is just thatit's going to be smarter and this soundslike a Dodge but I think that's likeamong the most remarkable facts in humanhistory that we can just do somethingand we can say right now with a highdegree of scientific certainty GPT 5 isgoing to be smarter than a lot smarterthan GPT 4 GPT 6 going to be a lotsmarter than gbt 5 and we are not nearthe top of this curve and we kind ofknow what know what to do and this isnot like it's going to get better in onearea this is not like we're going to youknow it's not that it's always going toget better at this eval or this subjector this modality it's just going to besmarter in the generalsense and I think the gravity of thatstatement is still like underrated okaythat's great Sam guys Sam is really herefor you he wants to answer your questionso we're going to open it up hello umthank you so much for joining joining usuh I'm a junior here at Stanford I sortof wanted to talk to you aboutresponsible deployment of AGI so as asyou guys could continually inch closerto that how do you plan to deploy thatresponsibly AI uh at open AI uh you knowto prevent uh you know stifling humanInnovation and continue to Spur that soI'm actually not worried at all aboutstifling of human Innovation I I reallydeeply believe that people will justsurprise us on the upside with bettertools I think all of history suggestthat if you give people more leveragethey do more amazing things and that'skind of like we all get to benefit fromthat that's just kind of great I amthough increasingly worried about howwe're going to do this all responsibly Ithink as the models get more capable wehave a higher and higher bar we do a lotof things like uh red teaming andexternal Audits and I think those areall really good but I think as themodels get more capable we'll have todeploy even more iteratively have aneven tighter feedback loop on looking athow they're used and where they work andwhere they don't work and this thisworld that we used to do where we canrelease a major model update everycouple of years we probably have to findways to like increase the granularity onthat and deploy more iteratively than wehave in the past and it's not superobvious to us yet how to do that but Ithink that'll be key to responsibledeployment and also the way we kind ofhave all of the stakeholders negotiatewhat the rules of AI need to be uhthat's going to get more comp Lex overtime too thank you next question wherehere you mentioned before that there's agrowing need for larger and largercomputers and faster computers howevermany parts of the world don't have theinfrastructure to build those datacenters or those large computers how doyou see um Global Innovation beingimpacted by that so two parts to thatoneum no matter where the computers arebuilt I think Global and Equitableaccess to use the computers for trainingas well inference is super important umone of the things that's like very C toour mission is that we make chat GPTavailable for free to as many people aswant to use it with the exception ofcertain countries where we either can'tor don't for a good reason want tooperate um how we think about makingtraining compute more available to theworld is is uh going to becomeincreasingly important I I do think weget to a world where we sort of thinkabout it as a human right to get accessto a certain amount of compute and wegot to figure out how to like distributethat to people all around the world umthere's a second thing though which is Ithink countries are going toincreasingly realize the importance ofhaving their own AI infrastructure andwe want to figure out a way and we'renow spending a lot of time travelingaround the world to build them in uh themany countries that'll want to buildthese and I hope we can play some smallrole there in helping that happen trficthankyou U my question was what role do youenvision for AI in the future of likespace exploration or likecolonization um I think space is likenot that hospitable for biological lifeobviously and so if we can send therobots that seemseasier hey Sam so my question is for alot of the founders in the room and I'mgoing to give you the question and thenI'm going to explain why I think it'scomplicated um so my question is abouthow you know an idea isnon-consensus and the reason I thinkit's complicated is cu it's easy tooverthink um I think today even yourselfsays AI is the place to start a companyI think that's prettyconsensus maybe rightfully so it's aninflection point I think it's hard toknow if idea is non-consensus dependingon the group that you're talking aboutthe general public has a different viewof tech from The Tech Community and evenTech Elites have a different point ofview from the tech community so I waswondering how you verify that your ideais non-consensus enough topursue um I mean first of all what youreally want is to be right beingcontrarian and wrong still is wrong andif you predicted like 17 out of the lasttwo recessions you probably werecontrarian for the two you got rightprobably not even necessarily um but youwere wrong 15 other times and andand so I think it's easy to get tooexcited about being contrarian and andagain like the most important thing tobe right and the group is usually rightbut where the most value is um is whenyou are contrarian andrightand and that doesn't always happen inlike sort of a zero one kind of way likeeverybody in the room can agree that AIis the right place to start the companyand if one person in the room figuresout the right company to start and thensuccessfully executes on that andeverybody else thinks ah that wasn't thebest thing you could do that's whatmatters so it's okay to kind of like gowith conventional wisdom when it's rightand then find the area where you havesome unique Insight in terms of how todo that um I do think surroundingyourself with the right peer group isreally important and finding originalthinkers uh is important but there ispart of this where you kind of have todo it Solo or at least part of it Soloor with a few other people who are likeyou know going to be your co-founders orwhateverum and I think by the time you're toofar in the like how can I find the rightpeer group you're somehow in the wrongframework already um so like learning totrust yourself and your own intuitionand your own thought process which getsmuch easier over time no one no matterwhat they said they say I think is liketruly great at this this when they'rejust starting out you because like youkind of just haven't built the muscleand like all of your Social pressure andall of like the evolutionary pressurethat produced you was against that soit's it's something that like you getbetter at over time and and and don'thold yourself to too high of a standardtoo early onit Hi Sam um I'm curious to know whatyour predictions are for how energydemand will change in the coming decadesand how we achieve a future whererenewable energy sources are 1 set perkilowatthourum I mean it will go up for sure wellnot for sure you can come up with allthese weird ways in whichlike we all depressing future is whereit doesn't go up I would like it to goup a lot I hope that we hold ourselvesto a high enough standard where it doesgo up I I I forget exactly what the kindof world's electrical gener generatingcapacity is right now but let's say it'slike 3,000 4,000 gwatt something likethat even if we add another 100 gwattfor AI it doesn't materially change itthat much but it changes it some and ifwe start at a th gwatt for AI someday itdoes that's a material change but thereare a lot of other things that we wantto do and energy does seem to correlatequite a lot with quality of life we candeliver for peopleum my guess is that Fusion eventuallydominates electrical generation on Earthum I think it should be the cheapestmost abundant most reliable densestsourceI could could be wrong with that and itcould be solar Plus Storage um and youknow my guess most likely is it's goingto be 820 one way or the other andthere'll be some cases where one ofthose is better than the other but uhthose kind of seem like the the two betsfor like really global scale one centper kilowatt hourenergy Hi Sam I have a question it'sabout op guide drop what happened lastyear so what's the less you learn cuzyou talk about resilience so what's thelesson you learn from left that companyand now coming back and what what madeyou com in back because Microsoft alsogave you offer like can you share moreum I mean the best lesson I learned wasthat uh we had an incredible team thattotally could have run the companywithout me and did did for a couple ofdaysum and you never and also that the teamwas super resilient like we knew that aCRA some crazy things and probably morecrazy things will happen to us betweenhere and AGI um as different parts ofthe world have stronger and strongeremotional reactions and the stakes keepratcheting up and you know I thoughtthat the team would do well under a lotof pressure but you never really knowuntil you get to run the experiment andwe got to run the experiment and Ilearned that the team was superresilient and like ready to kind of runthe company um in terms of why I cameback you know I originally when the soit was like the next morning the boardcalled me and like what do you thinkabout coming back and I was like no umI'm mad umand and then I thought about it and Irealized just like how much I loved openAI um how much I loved the people the Cthe culture we had built uh the missionand I kind of like wanted to finish itAltogether you you you emotionally I justwant to this is obviously a reallysensitive and one of one of oh it's it'snot but was I imagine that was okay wellthen can we talk about the structureabout it because this Russian dollstructure of the open AI where you havethe nonprofit owning the for-profit umyou know when we're we're trying toteach principal ger entrepreneur we gothere we got to the structure graduallyum it's not what I would go back andpick if we could do it all over againbut we didn't think we were going tohave a product when we started we werejust going to be like a AI research labwasn't even clear we had no idea about alanguage model or an API or chat GPT soif if you're going to start a companyyou got to have like some theory thatyou're going to sell a product somedayand we didn't think we were going to wedidn't realize we're were going to needso much money for compute we didn'trealize we were going to like have thisnice business um so what was yourintention when you started it we justwanted to like push AI research forwardwe thought that and I know this getsback to motivations but that's the puremotivation there's no motivation aroundmaking money or or power I cannotoverstate how foreign of a concept likeI mean for you personally not for openAI but you you weren't starting well Ihad already made a lot of money so itwas not like a big I mean I I like Idon't want to like claim some like moralPurity here it was just like that wasthe of my life a dver driver okaybecause there's this so and the reasonwhy I'm asking is just you know whenwe're teaching about principle drivenentrepreneurship here you can you canunderstand principles inferred fromorganizational structures when theUnited States was set up thearchitecture of governance is theConstitution it's got three branches ofgovernment all these checks and balancesand you can infer certain principlesthat you know there's a skepticism oncentralizing power that you know thingswill move slowly it's hard to get thingsto change but it'll be very verystable if you you know not to parotBilly eish but if you look at the openAI structure and you think what was thatmade for um it's a you have a like yournear hundred billion dollar valuationand you've got a very very limited boardthat's a nonprofit board which issupposed to look after it's it's itsfiduciary duties to the again it's notwhat we would have done if we knew thenwhat we know now but you don't get tolike play Life In Reverse and you haveto just like adapt there's a mission wereally cared about we thought we thoughtAI was going to be really important wethought we had an algorithm that learnedwe knew it got better with scale wedidn't know how predictably it gotbetter with scale and we wanted to pushon this we thought this was like goingto be a very important thing in humanhistory and we didn't get everythingright but we were right on the big stuffand our mission hasn't changed and we'veadapted the structure as we go and willadapt it more in the future um but youknow like youdon't like life is not a problem set umyou don't get to like solve everythingreally nicely all at once it doesn'twork quite like it works in theclassroom as you're doing it and myadvice is just like trust yourself toadapt as you go it'll be a little bitmessy but you can do it and I just askedthis because of the significance of openAI um you have a you have a board whichis all supposed to be independentfinancially so that they're making thesedecisions as a nonprofit thinking aboutthe stakeholder their stakeholder thatthey are fiduciary of isn't theshareholders it's Humanity umeverybody's independent there's noFinancial incentive that anybody hasthat's on the board including yourselfwith hope and AI um well Greg was I okayfirst of all I think making money is agood thing I think capitalism is a goodthing um my co-founders on the boardhave had uh financial interest and I'venever once seen them not take thegravity of the mission seriously um butyou know we've put a structure in placethat we think is a way to get umincentives aligned and I do believeincentives are superpowers but I'm surewe'll evolve it more over time and Ithink that's good not bad and with openAI the new fund you're not you don't getany carry in that and you're notfollowing on investments onto those okayokay okay thank you we can keep talkingabout this I I I know you want to goback to students I do too so we'll gowe'll keep we'll keep going to thestudents how do you expect that AGI willchange geopolitics and the balance ofpower in the world um like maybe morethan anyother technology um I don't I I thinkabout that so much and I have such ahard time saying what it's actuallygoing to do um I or or maybe moreaccurately I have such a hard timesaying what it won't do and we weretalking earlier about how it's like notgoing to CH maybe it won't changeday-to-day life that much but thebalance of power in the world it feelslike it does change a lot but I don'thave a deep answer of exactly howthanks so much um I was wondering sorryI was wondering in the deployment oflike general intelligence and alsoresponsible AI how much do you think isit necessary that AI systems are somehowcapable of recognizing their owninsecurities or like uncertainties andactually communicating them to theoutside world I I always get nervousanthropomorphizing AI too much because Ithink it like can lead to a bunch ofweird oversights but if we say like howmuch can AI recognize its ownflaws uh I think that's very importantto build and right now and the abilityto like recognize an error in reasoningum and have some sort of likeintrospection ability like that thatthat seems to me like really importanttopursue hey s thank you for giving ussome of your time today and coming tospeak from the outside looking in we weall hear about the culture and togethertogetherness of open AI in addition tothe intensity and speed of what you guyswork out clearly seen from CH gbt andall your breakthroughs and also in whenyou were temporarily removed from thecompany by the board and how all the allof your employees tweeted open air isnothing without its people what wouldyou say is the reason behind this is itthe binding mission to achieve AGI orsomething even deeper what is pushingthe culture everyday I think it is the shared Mission umI mean I think people like like eachother and we feel like we've you knowwe're in the trenches together doingthis really hard thing umbut I think it really is like deep senseof purpose and loyalty to the missionand when you can create that I think itis like the strongest force for Successat any start at least that I've seenamong startups um and you know we try tolike select for that and people we hirebut even people who come in not reallybelieving that AGI is going to be such abig deal and that getting it right is soimportant tend to believe it after thefirst three months or whatever and sothat's like that's a very powerfulcultural force that we havethanks um currently there are a lot ofconcerns about the misuse of AI in theimmediate term with issues like Globalconflicts and the election coming upwhat do you think can be done by theindustry governments and honestly PeopleLike Us in the immediate term especiallywith very strong open- Sourcemodels one thing that I think isimportant is not to pretend like thistechnology or any other technology isall good um I believe that AI will bevery net good tremendously net good umbut I think like with any other toolum it'll be misused like you can dogreat things with a hammer and you canlike kill people with a hammer um Idon't think that absolves us or you allor Society from um trying to mitigatethe bad as much as we can and maximizethe goodbut I do think it's important to realizethat with any sufficiently powerful Tooluh you do put Power in the hands of toolusers or you make some decisions thatconstrain what people in society can doI think we have a voice in that I thinkyou all have a voice on that I think thegovernments and our electedrepresentatives in Democratic processprocesses have the loudest voice inthat but we're not going to get thisperfectly right like we Society are notgoing to get this perfectly rightand a tight feedback loop I think is thebest way to get it closest to right umand the way that that balance getsnegotiated of safety versus freedom andautonomy um I think it's like worthstudying that with previous Technologiesand we'll do the best we can here weSociety will do the best we canhere um gang actually I've got to cut itsorry I know um I'm wanty to be verysensitive to time I know the theinterest far exceeds the time and thelove for Sam um Sam I know it is yourbirthday I don't know if you can indulgeus because I know there's a lot of lovefor you so I wonder if we can all justsing Happy Birthday no no no please nowe want to make you very uncomfortableone more question I'd much rather do onemorequestion this is less interesting to youthank you we can you can do one morequestionquickly day dearSam happy birthday to you20 seconds of awkwardness is there aburner question somebody who's got areal burner and we only have 30 secondsso make itshort um hi I wanted to ask if theprospect of making something smarterthan any human could possibly be scaresyou it of course does and I think itwould be like really weird and uh a badsign if it didn't scare me um humanshave gotten dramatically smarter andmore capable over time you aredramatically more capable than yourgreat great grandparents and there'salmost no biological drift over thatperiod like sure you eat a little bitbetter and you got better healthare ummaybe you eat worse I don't know um butthat's not the main reason you're morecapable um you are more capable becausethe infrastructure ofsociety is way smarter and way morecapable than any human and and throughthat it made you Society people thatcame before you um made you uh theinternet the iPhone a huge amount ofknowledge available at your fingertipsand you can do things that yourpredecessors would find absolutelybreathtakingum Society is far smarter than you nowum Society is an AGI as far as you cantell and thethe way that that happened was not anyindividual's brain but the space betweenall of us that scaffolding that we buildup um and contribute to Brick by Brickstep by step uh and then we use to go tofar greater Heights for the people thatcome after us um things that are smarterthan us will contribute to that samescaffolding um you willhave your children will have toolsavailable that you didn't um and thatscaffolding will have gotten built up toGreater Heightsand that's always a little bit scary umbut I think it's like more way more goodthan bad and people will do betterthings and solve more problems and thepeople of the future will be able to usethese new tools and the new scaffoldingthat these new tools contribute to um ifyou think about a world that has um AImaking a bunch of scientific discoverywhat happens to that scientific progressis it just gets added to the scaffoldingand then your kids can do new thingswith it or you in 10 years can do newthings with it um but the way it's goingto feel to people uh I think is not thatthere is this like much smarter entityuh because we're much smarter in somesense than the great great greatgrandparents are more capable at leastum but that any individual person canjust domore on that we're going to end it solet's give Sam a round of applause[Music]\n"
     ]
    }
   ],
   "source": [
    "transcript = YouTubeTranscriptApi.get_transcript(\"GLKoDkbS1Cg\")\n",
    "transcription=\"\"\n",
    "for i in transcript:\n",
    "    transcription+=i[\"text\"]\n",
    "print(transcription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"\"\"extract all points (make sure each point has full context of the data provided. dont use pronouns) from the data as they are and split each point with delimiter '@@@' return the response within a codeblock  for example -         \n",
    "```point1@@@\n",
    "point2@@@\n",
    "point3@@@\n",
    "...```\"\"\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": transcription\n",
    "        }\n",
    "    ],\n",
    "    temperature=1,\n",
    "    max_tokens=4096,\n",
    "    top_p=1,\n",
    "    frequency_penalty=0,\n",
    "    presence_penalty=0\n",
    ")\n",
    "points_list=response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```\n",
      "1. Sam Altman is the co-founder and CEO of openAI. @@@\n",
      "2. OpenAI is a nonprofit research lab with the mission to build general purpose artificial intelligence that benefits all of Humanity. @@@\n",
      "3. OpenAI set the record for the fastest growing app in history with the launch of chat GPT, growing to 100 million active users just two months after launch. @@@\n",
      "4. Sam was named one of Times's 100 most influential people in the world. @@@\n",
      "5. Sam's life is a pattern of breaking boundaries and transcending what's possible for himself and the world. @@@\n",
      "6. Sam co-founded openAI in 2015. @@@\n",
      "7. Sam has a husband and splits his time between San Francisco and Napa. @@@\n",
      "8. Resilience can be taught and will be more important in the coming decades, according to Sam. @@@\n",
      "9. Sam believes that Fusion will eventually dominate electrical generation on Earth. @@@\n",
      "10. Sam thinks that AI will be a net good, even though the technology can be misused. @@@\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"\"\"extract all points which can be answered true or false which can be used for factual validation and dont include points like introductory statements or anything that is not topic specific or content specific (make sure each point has full context of the data provided. dont use pronouns do not use pronouns DO NOT USE PRONOUNS) from the data as they are and add '@@@' after each point and return the response within a codeblock\"\"\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": transcription\n",
    "        }\n",
    "    ],\n",
    "    temperature=1,\n",
    "    max_tokens=4096,\n",
    "    top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "points_list=response.choices[0].message.content\n",
    "print(points_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_list=points_list[points_list.index('```')+3:points_list.rfind('```')].strip()\n",
    "points_list=points_list.replace('\\n',\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_list=points_list.split('@@@')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- OpenAI is the research and deployment company behind chat gbt Dolly and Sora. \n",
      "- Sam Altman is the co-founder and CEO of OpenAI, a nonprofit research lab with the mission to build general purpose artificial intelligence that benefits all Humanity. \n",
      "- OpenAI set the record for the fastest growing app in history with the launch of chat gbt which grew to 100 million active users just two months after launch. \n",
      "- Sam Altman studied computer science at Stanford and joined the inaugural class of Y combinator with a Social Mobile app company called looped. \n",
      "- Sam Altman became the president of Y Combinator from 2014 to 2019. \n",
      "- Sam Altman co-founded openAI as a nonprofit research lab with the mission to build general purpose artificial intelligence that benefits all Humanity. \n",
      "- OpenAI has a structure where the nonprofit owns the for-profit part of the organization. \n",
      "- The culture at OpenAI is driven by a shared mission and deep sense of purpose. \n",
      "- AI infrastructure is predicted to be one of the most important inputs to the future. \n",
      "- Peopledon't know yet what to expect from chat gbt five, but it is anticipated to be smarter than the previous versions. \n",
      "- Fusion or solar plus storage are seen as potential dominant sources of energy generation in the future. \n",
      "- OpenAI provides chat GPT for free to as many people as want to use it, with exceptions for certain countries. \n",
      "- AI has the potential to drastically change society, but the exact impact is hard to predict. \n",
      "- OpenAI has a structure with a nonprofit board and mechanisms in place to align incentives toward the mission of achieving AGI. \n",
      "- The balance between safety and freedom in deploying AI is a challenge that involves industry, governments, and individuals. \n",
      "- The prospect of creating something smarter than any human is a scary thought for Sam Altman, but it is seen as part of the natural progression of human technological advancement. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for point in points_list:\n",
    "    print(point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in points_list:\n",
    "    if i=='':\n",
    "        points_list.remove(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['- OpenAI is the research and deployment company behind chat gbt Dolly and Sora. ', '- Sam Altman is the co-founder and CEO of OpenAI, a nonprofit research lab with the mission to build general purpose artificial intelligence that benefits all Humanity. ', '- OpenAI set the record for the fastest growing app in history with the launch of chat gbt which grew to 100 million active users just two months after launch. ', '- Sam Altman studied computer science at Stanford and joined the inaugural class of Y combinator with a Social Mobile app company called looped. ', '- Sam Altman became the president of Y Combinator from 2014 to 2019. ', '- Sam Altman co-founded openAI as a nonprofit research lab with the mission to build general purpose artificial intelligence that benefits all Humanity. ', '- OpenAI has a structure where the nonprofit owns the for-profit part of the organization. ', '- The culture at OpenAI is driven by a shared mission and deep sense of purpose. ', '- AI infrastructure is predicted to be one of the most important inputs to the future. ', \"- Peopledon't know yet what to expect from chat gbt five, but it is anticipated to be smarter than the previous versions. \", '- Fusion or solar plus storage are seen as potential dominant sources of energy generation in the future. ', '- OpenAI provides chat GPT for free to as many people as want to use it, with exceptions for certain countries. ', '- AI has the potential to drastically change society, but the exact impact is hard to predict. ', '- OpenAI has a structure with a nonprofit board and mechanisms in place to align incentives toward the mission of achieving AGI. ', '- The balance between safety and freedom in deploying AI is a challenge that involves industry, governments, and individuals. ', '- The prospect of creating something smarter than any human is a scary thought for Sam Altman, but it is seen as part of the natural progression of human technological advancement. ']\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "print(points_list)\n",
    "print(len(points_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- OpenAI is the research and deployment company behind chat gbt Dolly and Sora. \n",
      "false\n",
      "\n",
      "\n",
      "- Sam Altman is the co-founder and CEO of OpenAI, a nonprofit research lab with the mission to build general purpose artificial intelligence that benefits all Humanity. \n",
      "true\n",
      "\n",
      "\n",
      "- OpenAI set the record for the fastest growing app in history with the launch of chat gbt which grew to 100 million active users just two months after launch. \n",
      "false\n",
      "\n",
      "\n",
      "- Sam Altman studied computer science at Stanford and joined the inaugural class of Y combinator with a Social Mobile app company called looped. \n",
      "false\n",
      "\n",
      "\n",
      "- Sam Altman became the president of Y Combinator from 2014 to 2019. \n",
      "false\n",
      "\n",
      "\n",
      "- Sam Altman co-founded openAI as a nonprofit research lab with the mission to build general purpose artificial intelligence that benefits all Humanity. \n",
      "false\n",
      "\n",
      "\n",
      "- OpenAI has a structure where the nonprofit owns the for-profit part of the organization. \n",
      "false\n",
      "\n",
      "\n",
      "- The culture at OpenAI is driven by a shared mission and deep sense of purpose. \n",
      "false\n",
      "\n",
      "\n",
      "- AI infrastructure is predicted to be one of the most important inputs to the future. \n",
      "false\n",
      "\n",
      "\n",
      "- Peopledon't know yet what to expect from chat gbt five, but it is anticipated to be smarter than the previous versions. \n",
      "false\n",
      "\n",
      "\n",
      "- Fusion or solar plus storage are seen as potential dominant sources of energy generation in the future. \n",
      "true\n",
      "\n",
      "\n",
      "- OpenAI provides chat GPT for free to as many people as want to use it, with exceptions for certain countries. \n",
      "false\n",
      "\n",
      "\n",
      "- AI has the potential to drastically change society, but the exact impact is hard to predict. \n",
      "false\n",
      "\n",
      "\n",
      "- OpenAI has a structure with a nonprofit board and mechanisms in place to align incentives toward the mission of achieving AGI. \n",
      "false\n",
      "\n",
      "\n",
      "- The balance between safety and freedom in deploying AI is a challenge that involves industry, governments, and individuals. \n",
      "false\n",
      "\n",
      "\n",
      "- The prospect of creating something smarter than any human is a scary thought for Sam Altman, but it is seen as part of the natural progression of human technological advancement. \n",
      "false\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for point in points_list:\n",
    "    print(point)\n",
    "    results = await AsyncDDGS().news(point, region='wt-wt', safesearch='off', timelimit='m', max_results=1)\n",
    "    loader = WebBaseLoader(results[0][\"url\"])\n",
    "    docs = loader.load()\n",
    "    \n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"\"\"you are a fact validator, your task is to check for statement[] in resource[] and return only true or false (lowercase) one word\"\"\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"statement[{point}],resource[{docs}]\"\n",
    "        }\n",
    "    ],\n",
    "        temperature=1,\n",
    "  max_tokens=256,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    "    )\n",
    "    relornot=response.choices[0].message.content\n",
    "    print(relornot)\n",
    "    print()\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
